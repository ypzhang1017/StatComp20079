---
title: "HW20079"
author: "20079"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{HW20079}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


# HW0-2020-09-20  
  
## Question  

Use knitr to produce 3 examples in the book. The 1st example should contain texts and at least one figure. The 2nd example should contains texts and at least one table. The 3rd example should contain at least a couple of LaTeX formulas.

## Answer  

1.Draw the scatter diagram of ozone and the density diagram with histogram of temp with the data set in R.
```{r echo=TRUE}
data(airquality)
#画散点图
plot(airquality$Ozone)
#画出密度图
plot(density(airquality$Temp))
hist(airquality$Temp,prob=T)
lines(density(airquality$Temp),col=3,lwd=4)
```

2.Generate a table by using the first five data of sequence, capital letters and month

```{r echo=TRUE}
library(knitr)
res <- data.frame(sep=1:5,name=LETTERS[1:5],month=month.abb[1:5])
knitr::kable(res)
```

3.Generate a set of equations with LaTeX
$\begin{equation}
\left\{
\begin{array}{lr}
x=\dfrac{3\pi}{2}(1+2t)\cos(\dfrac{3\pi}{2}(1+2t)), & \\
y=s, & 0\leq s\leq L,|t|\leq1.\\
z=\dfrac{3\pi}{2}(1+2t)\sin(\dfrac{3\pi}{2}(1+2t)), & 
\end{array}
\right.
\end{equation}$  
  
# HW1-2020-09-22
  
## Question  

3.3 The Pareto(a, b) distribution has cdf   
$$F(x)=1-(\frac{b}{x})^a,x≥b＞0，a＞0.$$ 

Derive the probability inverse transformation $F^{-1}(U)$ and use the inverse transform method to simulate a random sample from the Pareto(2, 2)distribution. Graph the density histogram of the sample with the Pareto(2, 2)density superimposed for comparison.


3.9  The rescaled Epanechnikov kernel [85] is a symmetric density function  

$$f_{e}(x)=\frac{3}{4}(1-x^2),|x|≤1. (3.10)$$

Devroye and $Gy\ddot{o}rfi$ [71, p. 236] give the following algorithm for simulation from this distribution. Generate iid $U_{1},U_{2},U_{3}$ ∼ Uniform(−1, 1). If $|U_{3}|≥|U_{2}|$ and $|U_{3}| ≥ |U_{1}|$, deliver $U_{2}$; otherwise deliver $U_{3}$. Write a function to generate random variates from $f_{e}$, and construct the histogram density estimate of a large simulated random sample.

3.10  Prove that the algorithm given in Exercise 3.9 generates variates from the density $f_{e}$ (3.10).


3.13  It can be shown that the mixture in Exercise 3.12 has a Pareto distribution
with cdf   

$$F(y)=1-(\frac{\beta}{\beta+y})^r,y≥0.$$

(This is an alternative parameterization of the Pareto cdf given in Exercise3.3.) Generate 1000 random observations from the mixture with r = 4 and $\beta$ = 2. Compare the empirical and theoretical (Pareto) distributions by graphing the density histogram of the sample and superimposing the Pareto density
curve.


## Answer

### 3.3  

Here $F_{X}(x)=1-(\frac{b}x)^a,x≥b＞0,a＞0$,
$f_{X}(x)=\frac{ab^a}{x^{a+1}}$and
$F_{X}^{-1}(u)=inf\left\{x:F_{X}(x)=u\right\}=$
$\frac{b}{\sqrt[a]{1-u}},0<u<1$  
For Pareto(2,2),  $F_{X}^{-1}(u)=\frac{2}{\sqrt[2]{1-u}}$
$f(x)=\frac{8}{x^3}$

```{r}
n <- 1000
u <- runif(n)
x <-2*(1-u)^(-1/2)
hist(x, prob = TRUE,main = expression(f(x)==8*x^(-3)))
y <- seq(2,1000)
lines(y,8*y^(-3) )
```
 
### 3.9




```{r}
n <- 1000
U1=runif(n,-1,1);U2=runif(n,-1,1);U3=runif(n,-1,1)
x <- c(1:n)
for (i in 1:n){
  if (abs(U3[i])>= abs(U2[i]) & abs(U3[i])>= abs(U1[i])) {
    x[i] <- U2[i]
  }else{
    x[i] <- U3[i]
  }
}
hist(x, prob = TRUE,main = expression(f(x)==3/4*(1-x^2)))
y <- seq(-1,1,.01)
lines(y,3/4*(1-y^2))




```
### 3.10   

Proof:  
(U1,U2,U3) is a random point in the cube [−1,1]^3. Let X be the distribution generated by the given algorithm: it is obviously a symmetric distribution supported on [−1, 1]. If we take some $\alpha \in [0,1]$, the probability that $|V|≤\alpha$ is given by the probability that $max(|U_{1}|,|U_{2}|≤|U_{3}|)$and $|U_{2}|≤\alpha$, plus the probability that $max(|U_{1}|,|U_{2}|>|U_{3}|)$ and $|U_{3}|≤\alpha$ hence by:
$P(X≤x)=\int_{0}^{\alpha}(\int_{u_{2}}^{1}\int_{u_{1}}^{1}du_{3}du_{1}+\int_{0}^{u_{2}}\int_{u_{2}}^{1}du_{3}du_{1})du_{2}+\int_{0}^{\alpha}(1-\int_{0}^{u_{3}}du_{1}\int_{0}^{u_{3}}du_{2})du_{3}$  
$=\frac{3\alpha-\alpha^3}{2}$  

That gives:
$P[0 ≤ X≤\alpha] =\frac{3\alpha-\alpha^3}{4}$

and by differentiating with respect to $\alpha$ we get that the p.d.f of X is given by $\frac{3}{4}(1-x^2)$





### 3.13  

Solve:  
We can see $\Lambda\sim Gamma(r,\beta)$,$Y|_{\Lambda=\lambda}\sim Exp(\lambda)$ from Exercise 3.12 .  

When r=4,$\beta$=2,$f(y)=\frac{64}{(2+y)^5}$

```{r}
n <- 1000; r <- 4; beta <- 2
lambda <- rgamma(n, r, beta)
y <- rexp(n, lambda) 
hist(y, prob = TRUE,main = expression(f(y)==64/(2+y)^5))
z <- seq(0,1000)
lines(z,64/(2+z)^5 )
```
  
# HW2-2020-10-13  

##Question1   

5.1 Compute a Monte Carlo estimate of
$$\int_{0}^{\pi/3}\sin t dt$$
and compare your estimate with the exact value of the integral.   

##Answer1    

Solve:  
A simple algorithm:  

(1)$\theta=\int_{0}^{\pi/3}\sin tdt=\int_{0}^{\pi/3}\frac{\pi}{3}\sin t\frac{1}{\frac{\pi}{3}}dt=E(\frac{\pi}3\sin t)$,where $T\sim U(0,\pi/3)$  

(2)Use a frequency to approximate the expectation (Strong Law of Large Number):  
$$\frac{1}{m}\sum_{i=1}^mg(T_{i})$$
where $g(t)=\frac{\pi}{3}\sin t$,and $T_{1},\ldots,T_{m}$ are i.i.d. copies of T and m is a sufficiently large integer.  
The theoretical value of $\theta$ is $1-\cos(\frac{\pi}3)$,so the R code for this question is as follows:

```{r}
m <- 1e4; t <- runif(m, min=0, max=pi/3)
theta.hat <- mean(sin(t))*(pi/3)
print(c(theta.hat,1-cos(pi/3)))
```

##Question2   

5.7 Refer to Exercise 5.6. Use a Monte Carlo simulation to estimate $\theta$ by the antithetic variate approach and by the simple Monte Carlo method. Compute an empirical estimate of the percent reduction in variance using the antithetic variate. Compare the result with the theoretical value from Exercise 5.6  
  
##Answer2   

Solve:  
The problem is to estimate $\theta=\int_{0}^1e^xdx$,  
A simple estimator is given by  
$$\hat\theta=\frac{1}{R}\sum_{j=1}^{R}e^{U_{j}}.U_{j}\sim U(0,1)$$  
The antithetic variable estimator is
$$\hat\theta'=\frac{1}{R}\sum_{j=1}^{m/2}(e^{U_{j}}+e^{1-U_{j}}),U_{j}\sim U(0,1).$$  
The R code for this question is as follows:$(MC1=\hat\theta,MC2=\hat\theta')$


```{r}
MC.Phi <-function(R = 10000,antithetic = TRUE) {
  u <- runif(R/2)
  if (!antithetic) v <- runif(R/2) else
  v <- 1 - u
  u <- c(u, v)
  g <- mean(exp(u))
  g
}
m <- 1000
MC1 <- MC2 <- numeric(m)
for (i in 1:m) {
  MC1[i] <- MC.Phi( R = 1000, anti = FALSE)
  MC2[i] <- MC.Phi(R = 1000)

}
print(c(sd(MC1),sd(MC2),(var(MC1) - var(MC2))/var(MC1)))
print(c(mean(MC2),mean(MC2),exp(1)-1))##Compare the result with the theoretical value

```
 
The percent reduction in variance using the control variate compared with the simple Monte Carlo estimate is 98.3781$\%.$.Therefore, it is more effective to use the control variable method to estimate.

##Question3  

5.11 If $\hat\theta_{1}$ and $\hat\theta_{2}$ are unbiased estimators of $\theta$ and $\hat\theta_{1}$ and $\hat\theta_{2}$are antithetic, we
derived that $c^* = 1/2$ is the optimal constant that minimizes the variance of $\hat\theta_{c}=c\hat\theta_{1}+(1−c)\hat\theta_{2}$. Derive $c^*$for the general case.That is,if$\hat\theta_{1}$ and $\hat\theta_{2}$are any two unbiased estimators of $\theta$, find the value $c^*$that minimizes the variance of the estimator 
$\hat\theta_{c} = c\hat\theta_{1}+(1−c)\hat\theta_{2}$. in equation (5.11).($c^*$ will be a function of the variances and the covariance of the estimators.)  

##Answer3  

Solve:  
$\begin{align}
Var(\hat\theta_{c})&=Var(c\hat\theta_{1}+(1−c)\hat\theta_{2})\\
&=Var(\hat\theta_{2})+c^2Var(\hat\theta_{1}-\hat\theta_{2})+2cCov(\hat\theta_{2},\hat\theta_{1}-\hat\theta_{2})\\
&=(cSd(\hat\theta_{1}-\hat\theta_{2})+\frac{Cov(\hat\theta_{2},\hat\theta_{1}-\hat\theta_{2})}{Sd(\hat\theta_{1}-\hat\theta_{2})})^2+Var(\hat\theta_{2})-\frac{Cov^2(\hat\theta_{2},\hat\theta_{1}-\hat\theta_{2})}{Var(\hat\theta_{1}-\hat\theta_{2})}\\
\end{align}$  
When $c=c^*\triangleq-\frac{Cov(\hat\theta_{2},\hat\theta_{1}-\hat\theta_{2})}{Var(\hat\theta_{1}-\hat\theta_{2})}$,The above variance reaches the minimum  
$Var(\hat\theta_{2})-\frac{Cov^2(\hat\theta_{2},\hat\theta_{1}-\hat\theta_{2})}{Var(\hat\theta_{1}-\hat\theta_{2})}$

# HW3-2020-10-20  

##Question1  

Exercises 5.13 $\qquad$ Find two importance functions $f_{1}$ and $f_{2}$ that are supported on $(1,\infty)$ and are ‘close’ to
$$g(x) = \frac{x^2}{\sqrt{2\pi}}e^{-x^2/2},\quad x > 1.$$
Which of your two importance functions should produce the smaller variance
in estimating
$$\int_{1}^{\infty}\frac{x^2}{\sqrt{2\pi}}e^{-x^2/2}dx$$
by importance sampling? Explain.  

##Answer1  

Solve:  
$f_{1}(x)$ is the pdf of N(1,1)
$$f_{1}(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{(x-1)^2}{2}}$$
$f_{2}(x)$is the pdf of $\chi^2(6)$
$$f_{2}(x)=\frac{x^2}{16}e^{-x/2}$$
The R code based on $f_{1}(x)$ and $f_{2}(x)$ is as follows:
```{r}
m <- 10000
theta.hat <- se <- numeric(2)
g <- function(x){exp(-x^2+log(x^2)-1/2*log(2*pi))*(x>1)}

x <- rnorm(m,1,1)
f_1 <- function(x){exp(-(x-1)^2/2-1/2*log(2*pi))}
fg <- g(x)/f_1(x)
theta.hat[1] <- mean(fg)
se[1] <- sd(fg)

x <- rchisq(m,6)
f_2 <- function(x){exp(-x/2+log(x^2)-log(16))}
fg <- g(x)/f_2(x)
theta.hat[2] <- mean(fg)
se[2] <- sd(fg)

print(c(theta.hat,se))
```
The variance of $f_{1}(x)$ is smaller because $f_{1}(x)$ is closer to g(x).

## Question2   

Exercises 5.15 $\qquad$ Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.  

## Answer2   

Solve:  
Now divide the interval (0,1) in to five sub-intervals, ((j-1)/5, j/5), j =  1, . . . , 5.
Then on the $j^{th}$ sub-interval variables are generated from the density
$$\frac{e^{-x}}{e^{-(j-1)/5}-e^{-j/5}},\frac{j-1}{5}<\frac{j}{5}$$
Use importance sampling on each sub-interval,the R code of the question  is as follows:
```{r}
M <- 10000; k <- 5
r <- M/k
N <- 50 
T2 <- numeric(k)
est <- matrix(0, N, 1)
g<-function(x) {exp(-x-log(1+x^2))*(x>0)*(x<1)}
for (i in 1:N) {
  for(j in 1:k) {
    u <- runif(M)
    x <- -log((exp(-(j)/5)+u*(exp(-(j-1)/5)-exp(-j/5))))
    f <-function(x) exp(-x)/(exp(-(j-1)/5)-exp(-j/5))
    T2[j]<-mean(g(x)/f(x))
    est[i, 1] <- mean(T2)
  }
  est[i, 1] <- sum(T2)
}
u <- runif(M)
x <- - log(1 - u * (1 - exp(-1)))
fg <- g(x) / (exp(-x) / (1 - exp(-1)))
theta.hat <- mean(fg)
se <- sd(fg)
theta.hat
apply(est,2,mean)
se
apply(est,2,sd)
```
Obviously the variance of stratified importance sampling is smaller.

## Question3  

Exercises 6.4 $\qquad$ Suppose that $X_{1}\cdots X_{n}$ are a random sample from a from a lognormal distribution with unknown parameters. Construct a 95% confidence interval for the parameter $\mu$. Use a Monte Carlo method to obtain an empirical estimate of the confidence level.  

## Answer3    

Solve:
$X\sim LN(\mu,\sigma^2)$,then $Y=\ln(X)\sim N(\mu,\sigma^2)$,Use t distribution to construct a 95% confidence interval for the parameter $\mu$,  
$[\bar y-t_{1-\alpha/2}(n-1)s/\sqrt{n}]$,let n=100,$\mu=0,\sigma^2=1,$ 

The R code of the question  is as follows:
```{r}
n <- 100
alpha <- .05
f <- function(x) {LCL = mean(x)-sd(x)*qt(1-alpha/2,n-1)/sqrt(n)
UCL = mean(x)+sd(x)*qt(1-alpha/2,n-1)/sqrt(n)
return(c(LCL,UCL))
}
g <- replicate(1000,expr = {x <- log(rlnorm(n)) 
f(x)})
mean((0>g[1,]) & (0 < g[2,]))

```
The result fluctuates around 0.95.  


## Question4  

Exercises 6.5 $\qquad$ Suppose a 95% symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $\chi^2(2)$ data with sample size n = 20. Compare your t-interval results with the simulation results in Example 6.4. (The t-interval should be more robust to departures from normality than the interval for variance.)  

## Answer4   

Solve:  
The R code of the question  is as follows:
```{r}
n <- 20
alpha <- .05
x <- rchisq(n,2)
f <- function(x) {LCL = mean(x)-sd(x)*qt(1-alpha/2,n-1)/sqrt(n)
UCL = mean(x)+sd(x)*qt(1-alpha/2,n-1)/sqrt(n)
return(c(LCL,UCL))
}
g <- replicate(1000,expr = {x <- x <- rchisq(n,2) 
f(x)})
mean((2>g[1,]) & (2 < g[2,]))

```
The confidence interval coverage generated by using the t interval is smaller than that of Example 6.4.  
# HW4-2020-10-27  

## Question1-6.7  

Estimate the power of the skewness test of normality against symmetric Beta$(\alpha,\alpha)$ distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as $t(\nu)$?   


## Answer1-6.7  

Solve:Let the confidence level a=0.05  

The R code for this question is as follows:
```{r}
a <- 0.05
n <- 100
alpha <- c(seq(0.1,1,0.1),seq(1, 100, 10))#parameters of beta(alpha,alpha) distribution
t<-seq(1,100,5)
N <- length(alpha)
pwr1 <- pwr2 <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-a/2,0,sqrt(6*(n-2)/((n+1)*(n+3))))
sk <- function(x){
  #computes the sample skewness coeff
  xbar <- mean(x)
  m3 <- mean((x - xbar)^3)
  m2 <- mean((x - xbar)^2)
  return( m3 / m2^1.5 )
}
m <- 2500
for (j in 1:N) { #for each beta
  e <- alpha[j]
  sktests1 <- sktests2 <-  numeric(m)
  for (i in 1:m) { #for each replicate
    x <- rbeta(n, e, e)
    y <- rt(n,t[j])
    sktests1[i] <- as.integer(abs(sk(x)) >= cv)
    sktests2[i] <- as.integer(abs(sk(y)) >= cv)
  }
  pwr1[j] <- mean(sktests1)
  pwr1[j] <- mean(sktests1)
}

#plot power vs alpha
plot(alpha, pwr1, type = "b",
     xlab = bquote(alpha), ylim = c(0,.2))
abline(h = .1, lty = 3)
se <- sqrt(pwr1 * (1-pwr1) / m) #add standard errors
lines(alpha, pwr1+se,  lty = 3)
lines(alpha, pwr1-se,  lty = 3)

#plot power vs parameters of t distribution
plot(t, pwr2, type = "b", xlab = "parameters of t distribution", ylim = c(0,1),col="red")
se2 <- sqrt(pwr2* (1-pwr2) / m) 
#add standard errors 
lines(t, pwr2+se2, lty = 3,col="red") 
lines(t, pwr2-se2, lty = 3,col="red")

#when put them together
plot(alpha, pwr1, type = "b", xlab = "parameters of distribution", ylab = "pwr", ylim = c(0,1))
lines(t, pwr2, type = "b", xlab = "t", ylim = c(0,1),col="red")
abline(h = .05, lty = 3,col="red")
legend("topright",
       legend =c("beta","t") ,
       lty=3,
       col=c("black",'red'))
```
As can be seen from the figure above, with the increase of alpha, the power of beta distribution skewness normality test becomes smaller and smaller when alpha is small.
When alpha is relatively large, power of beta distribution skewness normality test becomes larger and larger.  
Different from the symmetric beta distribution, the potential function of the thick-tailed distribution t (v) is greater than 0.05, and with the increase of freedom, power decreases and tends to 0.05 gradually.
Therefore, the T-distribution and the normal distribution are closer than the symmetric beta distribution, which is also consistent with the intuition.

## Question2-6.8  

Refer to Example 6.16. Repeat the simulation, but also compute the $\mathit{F}$ test of equal variance, at significance level $\hat\alpha\dot{=}0.055$ Compare the power of the Count Five test and $\mathit{F}$ test for small, medium, and large sample sizes. (Recall that the $\mathit{F}$ test is not applicable for non-normal distributions.)  
  
## Answer2-6.8  

Solve:Sample size is taken separately 20,100,1000 
The R code for this question is as follows:
```{r}
n <- c(20,100,1000)#sample size
m <- 10000
sigma1 <- 1
sigma2 <- 1.5
power <- power2 <-  numeric(length(n))
count5test <- function(x,y){
  X <- x-mean(x)#centered by sample mean
  Y <- y-mean(y)
  outx <- sum(X>max(Y))+sum(X<min(Y))
  outy <- sum(Y>max(X))+sum(Y<min(X))
  return(as.integer(max(c(outx,outy))>5))
}
for(i in 1:length(n)){
  power[i] <- mean(replicate(m,expr = {
  x <- rnorm(n[i],0,sigma1)
  y <- rnorm(n[i],0,sigma2)
  count5test(x,y)
  }))
  pvalues <- replicate(m,expr={
    x <- rnorm(n[i],0,sigma1)
    y <- rnorm(n[i],0,sigma2)
    Ftest <- var.test(x, y, ratio = 1,
                      alternative = c("two.sided", "less", "greater"),
                      conf.level = 0.945, ...)
    Ftest$p.value})
  power2[i] <- mean(pvalues<=0.055)
}
power

power2
```
As can be seen from the results, power increases as the sample size increases.
Secondly, power is relatively large in small, medium and large samples.
In addition, the Power of the F test is larger than the CountFive test for small, medium, and large samples.



## Question3-6.C   


Repeat Examples 6.8 and 6.10 for Mardia’s multivariate skewness test. Mardia [187] proposed tests of multivariate normality based on multivariate generalizations of skewness and kurtosis. If $X$ and $Y$ are iid, the multivariate population skewness $\beta_{1,d}$ is defined by Mardia as
$$\beta_{1,d}=E[(X-\mu)^T\Sigma^{-1}(Y-\mu)]^3$$
Under normality,$\beta_{1,d}$. The multivariate skewness statistic is
$$b_{1,d}=\frac{1}{n^2}\sum_{i,j=1}^n((X_{i}-\bar X)^T\hat\Sigma^{-1}(X_{j}-\bar X))^3 \qquad \qquad \qquad \qquad (6.5)$$
where $\hat\Sigma$ is the maximum likelihood estimator of covariance. Large values of $b_{1,d}$ are significant. The asymptotic distribution of $nb_{1,d}/6$ is chisquared with d(d + 1)(d + 2)/6 degrees of freedom.  

## Answer3-6.C   

Solve:
The R code for this question is as follows:
```{r}
##Examples 6.8
set.seed(123)
library(MASS)
alpha <- 0.05
d <- 2
n <- c(10,20,30,40,50,100,500) #sample size
cv1 <- qchisq(1-alpha/2,d*(d + 1)*(d + 2)/6) #crit.values for each n
cv2 <- qchisq(alpha/2,d*(d + 1)*(d + 2)/6)
msk <- function(x) {
  xbar <- mean(x)
  n <- nrow(x)
  msk <- 1/n^2*sum(((x-xbar)%*%solve(cov(x))%*%t(x-xbar))^3)
  return(msk*n/6)
}

p.reject <- numeric(length(n))
m <- 1000
s <- matrix(c(1,0,0,1),2,2)
for (i in 1:length(n)) {
  sktests <- numeric(m)  #test decisions
  for (j in 1:m) {
    x <- mvrnorm(n[i],c(0,0),s)
    sktests[j] <- as.integer(msk(x) >= cv1 | msk(x) <= cv2)
  }
  p.reject[i] <- mean(sktests)
}
p.reject
```
```{r}
##Examples 6.10
library(MASS)
set.seed(123)
alpha<-0.05
d<-2
n <-20 #sample sizes 
cv <- qchisq(1-alpha,d*(d+1)*(d+2)/6) #crit. values for each n
sk <-function(x) { 
  n<-nrow(x)
  for (i in 1:d) {
    x[,i]<-x[,i]-mean(x[,i])
  }
  s<-solve(cov(x))
  b<-mean((x%*%s%*%t(x))*(x%*%s%*%t(x))*(x%*%s%*%t(x)))
  return(b*n/6)
}

m <- 1000
epsilon <- c(seq(0, .15, .05), seq(.15, 0.9, .15)) 
N <- length(epsilon) 
pwr <- numeric(N) #critical value for the skewness test 

for (j in 1:N) {
  e <- epsilon[j] 
  sktests <- numeric(m) 
  for (i in 1:m) {
    sig <- sample(c(1,10), replace = TRUE, size = n, prob = c(1-e, e))
    x <- mvrnorm(n,rep(0,d),diag(rep(sig[1],d)))
    for (k in 2:n) {
      sigma<-diag(rep(sig[k],d))
      x <- rbind(x,mvrnorm(n,rep(0,d),sigma))
    }
    sktests[i] <- as.integer(sk(x) >= cv) 
  }
  pwr[j] <- mean(sktests) 
}
#plot power vs epsilon 
plot(epsilon, pwr, type = "b", xlab = bquote(epsilon), ylim = c(0,1))
abline(h = .1, lty = 3) 
se <- sqrt(pwr * (1-pwr) / m) #add standard errors 
lines(epsilon, pwr+se, lty = 3) 
lines(epsilon, pwr-se, lty = 3)

```


## Question4- Discussion   


If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: say, 0.651 for one method and 0.676 for another method. Can we say the powers are different at 0.05 level?  

$\qquad$What is the corresponding hypothesis test problem?   
$\mathbf{Answer4- Discussion}$: Suppose the power function of the first method is $power_{1}$, and the power function of the second method is $power_{2}$,then$$H_{0}:power_{1}=power_{2}\leftrightarrow H_{1}:power_{1}\neq power_{2}$$

$\qquad$ What test should we use? Z-test, two-sample t-test, paired-t-test or McNemar test?   
## Answer4- Discussion  

We can use paired-t-test or Z-test or McNemar test but not two-sample t-test.Because two-sample t-test requires two samples to be independent.  

McNemar Test :
First, the data is preprocessed, that is, if $H_0$is true, $\frac {(x_i-y_i)^2} {x_i+y_i} \sim \chi^2_1$, and the null hypothesis is tested according to this expression.

$\qquad$ What information is needed to test your hypothesis?  
$\mathbf{Answer4- Discussion}$ :We need the power function generated from the sample data and the corresponding $\frac {(x_i-y_i)^2} {x_i+y_i} \sim \chi^2_1$.
We also need the chi-square quantile.   

# Hw5-2020-11-03  


## Question1-7.1   

Compute a jackknife estimate of the bias and the standard error of the correlation statistic in Example 7.2.  

## Answer1-7.1  
Solve:  
Jackknife estimate of bias:
$$\widehat{bias_{jack}}=(n-1)(\overline{\hat\theta_{(.)}}-\hat\theta)$$  
Jackknife estimate of standard error:
$$\hat{se}_{jack}=\sqrt{\frac{n-1}{n}\sum_{i=1}^n(\hat\theta_{i}-\overline{\hat\theta_{(.)}})^2}$$  
The R code for this problem is as follows:

```{r}
set.seed(123)
data(law,package = "bootstrap")
n <- nrow(law)
y <- law$LSAT
z <- law$GPA
R.hat <- cor(y,z)
#compute the jackknife replicates,leave-one-out estimates
R.jack <- numeric(n)
for (i in 1:n) 
  R.jack[i] <- cor(y[-i],z[-i])
bias <- (n-1)*(mean(R.jack)-R.hat)
print(bias)#jackknife estimate of bias

se <- sqrt((n-1)*mean((R.jack-mean(R.jack))^2))
print(se)# jackknife estimate of standard error

hist(R.jack,prob=TRUE)

```


## Question2-7.5  

Refer to Exercise 7.4. Compute 95% bootstrap confidence intervals for the mean time between failures $1/\lambda$ by the standard normal, basic, percentile,
and BCa methods. Compare the intervals and explain why they may differ.  

## Answer2-7.5  

Solve:  
The R code for this problem is as follows:  

method 1
```{r}
library(boot)
data('aircondit')
boot.obj <- boot(aircondit,R=2000,
                 statistic = function(x,i){mean(x[i,1])})
print(boot.ci(boot.obj,type = c("basic","norm","perc")))

boot.BCa <- function(x,th0,th,stat,conf=.95){
  x <- as.matrix(x)
  n <- nrow(x)
  N <- 1:n
  alpha <- (1+c(-conf,conf))/2
  zalpha <- qnorm(alpha)
  z0 <- qnorm(sum(th<th0)/length(th))
  th.jack <- numeric(n)
  for (i in 1:n) {
    J <- N[1:(n-1)]
    th.jack[i] <- stat(x[-i, ],J)
  }
  L <- mean(th.jack)-th.jack
  a <- sum(L^3)/(6*sum(L^2)^1.5)
  adj.alpha <- pnorm(z0+(z0+zalpha)/1-a*(z0+zalpha))
  limits <- quantile(th,adj.alpha,type = 6)
  return(list("est"=th0,"BCa"=limits))
}
n <- nrow(aircondit)
B <- 2000
x <- aircondit$hours
theta.b <- numeric(B)
theta.hat <- mean(x)
for (b in 1:B) {
  i <- sample(1:n,size = n,replace = TRUE)
  x <- aircondit$hours[i]
  theta.b[b] <- mean(x)
}
stat <- function(dat,index){
  mean(dat[index])
}
boot.BCa(x,th0 = theta.hat,th=theta.b,stat=stat)


```
method 2
```{r}
library(boot)
data('aircondit')
boot.obj <- boot(aircondit,R=2000,
                 statistic = function(x,i){mean(x[i,1])})
print(boot.ci(boot.obj,type = c("basic","norm","perc","bca")))
```  
All intervals cover 108.0833. One reason for the difference in the percentile and normal confidence intervals could be that the sampling distribution of statistic is not close to normal . When the sampling distribution of the statistic is approximately normal, the percentile interval will agree with the normal interval.



## Question3-7.8  

Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard error of $\hat\theta$  

## Answer3-7.8  

Solve:  
The R code for this problem is as follows:
```{r message=FALSE}
set.seed(0)
library(boot)
library(bootstrap)
data("scor")
lambda.hat <- eigen(cov(scor))$values
theta.hat <- lambda.hat[1]/sum(lambda.hat)
n <- nrow(scor) # number of rows (data size)
theta.j <- rep(0, n)
for (i in 1:n) {
  x <- scor [-i,]
  lambda <- eigen(cov(x))$values
  theta.j[i] <- lambda[1] / sum(lambda)
  # the i-th entry of theta.j is the i-th "leave-one-out" estimation of theta
}
bias.jack <- (n - 1) * (mean(theta.j) - theta.hat)
# the estimated bias of theta.hat, using jackknife
se.jack <- (n - 1) * sqrt(var(theta.j) / n)
# the estimated se of theta.hat, using jackknife
bias.jack
se.jack
```


## Question4-7.11  


In Example 7.18, leave-one-out (n-fold) cross validation was used to select the
best fitting model. Use leave-two-out cross validation to compare the models.  

## Answer4-7.11 
Solve:  
The R code for this problem is as follows:
```{r message=FALSE}
library(DAAG)
attach(ironslag)
n <- length(magnetic)#in DAAG ironslag
e1 <- e2 <- e3 <- e4 <- matrix(0,n,n)
# for n-fold cross validation
# fit models on leave-two-out samples
for (k in 1:(n-1)) {
  for (i in (k+1):n) {
    y <- magnetic[-c(k,i)]
    x <- chemical[-c(k,i)]
    
  J1 <- lm(y ~ x)
  yhat1 <- J1$coef[1]+J1$coef[2]*chemical[c(k,i)]
  e1[k,i] <- mean((magnetic[c(k,i)]-yhat1)^2)
  
  J2 <- lm(y~x+I(x^2))
  yhat2 <- J2$coef[1]+J2$coef[2]*chemical[c(k,i)]+
    J2$coef[3]*chemical[c(k,i)]^2
  e2[k,i] <- mean((magnetic[c(k,i)]-yhat2)^2)
  
  J3 <- lm(log(y)~x)
  logyhat3 <- J3$coef[1]+J3$coef[2]*chemical[c(k,i)]
  yhat3 <- exp(logyhat3)
  e3[k,i] <- mean((magnetic[c(k,i)]-yhat3)^2)
  
  J4 <- lm(log(y)~log(x))
  logyhat4 <- J4$coef[1]+J4$coef[2]*log(chemical[c(k,i)])
  yhat4 <- exp(logyhat4)
  e4[k,i] <- mean((magnetic[c(k,i)]-yhat4)^2)
  }
}

c(2*sum(e1)/(n*(n-1)),2*sum(e2)/(n*(n-1)),2*sum(e3)/(n*(n-1)),2*sum(e4)/(n*(n-1)))



```
According to the prediction error criterion, Model 2, the quadratic model,
would be the best fit for the data.    

# HW6-2020-11-10  


## Question1-8.3  
The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal.  

## Answer1-8.3  

Solve:  
The hypothesis test is: $$H_{0}:VarX=VarY\longleftrightarrow H_{1}:VarX\neq VarY$$  
We implement a permutation test for equal variance based on the maximum number of extreme points.  
Reject $H_0$ at significance level $\alpha$ if $\hat{p} \leq \alpha$.  
We estimate the type1 error based on 1000 Monte Carlo experiments, and we set the significance level at 0.05



```{r}
set.seed(12345)
maxout <- function(x,y){
  X <- x-mean(x)
  Y <- y-mean(y)
  outx <- sum(X>max(Y))+sum(X<min(Y))
  outy <- sum(Y>max(X))+sum(Y<min(X))
  return(max(c(outx,outy)))
}
alpha <- 0.05
n1 <- 20;n2 <- 30 #two different sample size
mu1 <- mu2 <- 0
sigma1 <- sigma2 <- 1
m <- 1000 # the times of Monte Carlo experiments
p_value <- replicate(m,expr = {
  x <- rnorm(n1,mu1,sigma1)
  y <- rnorm(n2,mu2,sigma2)
  ts <- numeric(199+1)
  ts[1] <- maxout(x,y)
  for (i in 1:199) {
    ind <- sample(1:(n1+n2),size=n1,replace = FALSE)
    x1 <- c(x,y)[ind];y1 <- c(x,y)[-ind] #complement of x1
    ts[i+1] <- maxout(x1,y1)
  }
  mean(ts>=ts[1])
})
#estimate the type1 error
print(mean(p_value<alpha))


```
As a result, we can see that the permutation method control the type1 error quite well.  


## Question2  

Design experiments for evaluating the performance of the NN,energy, and ball methods in various situations.  

$\qquad$Unequal variances and equal expectations.  

$\qquad$Unequal variances and unequal expectations.  

$\qquad$Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodel distribution (mixture of two normal distributions)  

$\qquad$Unbalanced samples (say, 1 case versus 10 controls)  

$\qquad$ Note: The parameters should be chosen such that the powers
are distinguishable (say, range from 0.3 to 0.8).  
## Answer2  

```{r}
#R packages that may be used
library(RANN)
library(energy)
library(Ball)
library(boot)

#Functions that may be used
Tn <- function(z,ix,sizes,k){
  n1 <- sizes[1];n2 <- sizes[2];n <- n1+n2
  if(is.vector(z)) z <- data.frame(z,0)
  z <- z[ix,]
  NN <- nn2(data=z,k=k+1)
  block1 <- NN$nn.idx[1:n1,-1]
  block2 <- NN$nn.idx[(n1+1):n,-1]
  i1 <- sum(block1 <- n1+0.5);i2 <- sum(block2>n1+0.5)
  (i1+i2)/(k*n)
}
eqdist.nn <- function(z,sizes,k){
  boot.obj <- boot(data=z,statistic = Tn,R=R,
                   sim = "permutation",sizes=sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
  p.value <- mean(ts>=ts[1])
  list(statistic=ts[1],p.value=p.value)
}
#1.Unequal variances and equal expectations,mu=0, sigma1=1,sigma2=2.
m <- 100;k <- 3;p <- 2
n1 <- n2 <- 10;R <- 999;n <- n1+n2;N=c(n1,n2)
p.values <- matrix(NA,m,3)
for (i in 1:m) {
  x <- matrix(rnorm(n1*p,0,3),ncol = p);
  y <- matrix(rnorm(n2*p,0,2),ncol=p);
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
  
}
alpha <- 0.3
pow1 <- colMeans(p.values<alpha)
pow1

#2.Unequal variances and unequal expectations,mu1=0,mu2=1,sigma1=1,sigma2=2
n1 <- n2 <- 10;n <- n1+n2;N=c(n1,n2)
p.values <- matrix(NA,m,3)
for (i in 1:m) {
  x <-matrix(rnorm(n1*p,0,1),ncol = p)
  y <- matrix(rnorm(n2*p,1,2),ncol=p)
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
  
}
alpha <- 0.1
pow2 <- colMeans(p.values<alpha)
pow2

#3.Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodel distribution (mixture of two normal distributions,where mu1=0,mu2=1,sigma1=sigma2=1)
p.values <- matrix(NA,m,3)
for (i in 1:m) {
  x <- matrix(rt(n1*p,1),ncol = p);
  y <- cbind(rnorm(n2),rnorm(n2,mean = 1))
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
  
}
alpha <- 0.1
pow3 <- colMeans(p.values<alpha)
pow3

#4.Unbalanced samples (say, 1 case versus 10 controls)

n1 <- 30;n2 <- 20;R <- 999;n <- n1+n2;N=c(n1,n2)
p.values <- matrix(NA,m,3)
for (i in 1:m) {
  x <- matrix(rnorm(n1*p,0,3.5),ncol = p);
  y <- matrix(rnorm(n2*p,0,2),ncol=p);
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
  p.values[i,3] <- bd.test(x=x,y=y,R=999,seed=i*12345)$p.value
  
}
alpha <- 0.1
pow4 <- colMeans(p.values<alpha)
pow4

```
For unequal variances and equal expectations, we can see that the ball method has the best power, which is 0.59. Then the power of energy method is 0.43. The power of NN method has the smallest power, which is 0.56. So  NN methods is best.   

For Unequal variances and unequal expectations, we can see that the ball method has the best power, which is 0.22. Then the power of energy method is 0.75. The power of NN method has the smallest power, which is 0.84. So  ball methods is best.  
For Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodel distribution (mixture of two normal distributions), we can see that the ball method has the best power, which is 0.66. Then the power of energy method is 0.64. The power of NN method has the smallest power, which is 0.73. So  ball methods is best.  
ForUnbalanced samples , we can see that the ball method has the best power, which is 0.62. Then the power of energy method is 0.49. The power of NN method has the smallest power, which is 0.91.So  ball methods is best. 

# HW8-2020-11-17 

## Question1-9.4  

Implement a random walk Metropolis sampler for generating the standard
Laplace distribution (see Exercise 3.2). For the increment, simulate from a normal distribution. Compare the chains generated when different variances are used for the proposal distribution. Also, compute the acceptance rates of each chain.  

## Answer1-9.4  

Solve:  
The standard Laplace distribution is $\frac{1}{2}e^{-|x|}$, so $$r(x_t,y)=\frac{f(Y)}{f(X_t)}=e^{|x_t|-|y|}$$
```{r}
r <- function(x,y){
  exp(abs(x)-abs(y))
}
#a function to implement the random walk Metropolis sampler to generate the standard Laplace distribution
rw.Metropolis <- function(x0,sigma,N){
  #x0: the initial point
  #sigma: the standard deviation in the normal distribution
  #N: the length of the chain
  x <- numeric(N)
  x[1] <- x0
  u <- runif(N)
  k <- 1 #count reject
  for (i in 2:N) {
    y <- rnorm(1,x[i-1],sigma)
    if(u[i]<=r(x[i-1],y)){
      x[i] <- y;k <- k+1
    }else{
      x[i]<x[i-1]
    }
  }
  return(list(x=x,k=k))
}

#generate the chain under different sigma in the proposed distribution
N <- 5000
sigma <- c(0.05,0.5,2,4,8,16)
x0 <- 20
for (i in 1:length(sigma)) {
  assign(paste0("rw",i),rw.Metropolis(x0,sigma[i],N))
}

#plot the chains under different sigma
index <- 1:N
for (i in 1:length(sigma)) {
  plot(index,get(paste0("rw",i))$x,type = "l",ylab = "x",xlab = "",
       main = bquote(sigma==.(sigma[i])))
}
#We can see the first chain with $\sigma = 0.05$ doesn't converge at 2000 times.

#Here we compute the accpetance rate:
a <- matrix(0,nrow = 1,ncol = length(sigma))
rownames(a) <- "acceptance rate"
col_name <- character(length(sigma))
for (i in 1:length(sigma)) {
  col_name[i] <- paste0("sigma=",sigma[i])
  a[1,i] <- get(paste0("rw",i))$k/N
}
colnames(a) <- col_name
knitr::kable(a)
```


## Question2  

For Exercise 9.4, use the Gelman-Rubin method to monitor convergence of the chain, and run the chain until it converges approximately to the target distribution according to $\hat R<1.2$.  

## Answer2  

Solve:  
```{r}
Gelman.Rubin <- function(psi) {
  # psi[i,j] is the statistic psi(X[i,1:j])
  # for chain in i-th row of X
  psi <- as.matrix(psi)
  n <- ncol(psi)
  k <- nrow(psi)
  psi.means <- rowMeans(psi) #row means
  B <- n * var(psi.means) #between variance est.
  psi.w <- apply(psi, 1, "var") #within variances
  W <- mean(psi.w) #within est.
  v.hat <- W*(n-1)/n + (B/n) #upper variance est.
  r.hat <- v.hat / W #G-R statistic
  return(r.hat)
}

r <- function(x,y){
  exp(abs(x)-abs(y))
}

rw.Metropolis <- function(x0,sigma,N){
  #x0: the initial point
  #sigma: the standard deviation in the normal distribution
  #N: the length of the chain
  x <- numeric(N)
  x[1] <- x0
  u <- runif(N)
  for (i in 2:N) {
    y <- rnorm(1,x[i-1],sigma)
    if(u[i]<=r(x[i-1],y)){
      x[i] <- y
    }else{
      x[i]<x[i-1]
    }
  }
  return(x)
}
  
sigma <- 1 #parameter of proposal distribution
k <- 4 #number of chains to generate
n <- 15000 #length of chains
b <- 1000 #burn-in length
  
#choose overdispersed initial values
x0 <- c(-10, -5, 5, 10)
  
#generate the chains
X <- matrix(0, nrow=k, ncol=n)
for (i in 1:k){
  X[i, ] <- rw.Metropolis(x0[i],sigma, n )
}  
  #compute diagnostic statistics
psi <- t(apply(X, 1, cumsum))
for (i in 1:nrow(psi)) {
  psi[i,] <- psi[i,] / (1:ncol(psi))
}
print(Gelman.Rubin(psi))
  
  #plot psi for the four chains
#par(mfrow=c(2,2))
for (i in 1:k) {
  plot(psi[i, (b+1):n], type="l",
         xlab=i, ylab=bquote(psi))
}
#par(mfrow=c(1,1)) #restore default
  
  #plot the sequence of R-hat statistics
rhat <- rep(0, n)
for (j in (b+1):n) {
  rhat[j] <- Gelman.Rubin(psi[,1:j])
}
plot(rhat[(b+1):n], type="l", xlab="", ylab="R")
abline(h=1.1 , lty=2)
```
From this plot it is evident that the chain is converging faster than when the proposal distribution had a very small variance. The value of $\hat R$ is below 1.2  and below 1.1 within 500 iterations.


## Question3-11.4  

Find the intersection points A(k) in $(0,\sqrt{k})$ of the curves
$$S_{k-1}(a)=P(t(k-1)>\sqrt{\frac{a^2(k-1)}{k-a^2}})$$
and
$$S_{k}(a)=P(t(k)>\sqrt{\frac{a^2k}{k+1-a^2}}),$$
for k = 4 : 25, 100, 500, 1000, where t(k) is a Student t random variable with k degrees of freedom. (These intersection points determine the critical values for a t-test for scale-mixture errors proposed by Sz´ekely [260].)  

## Answer3-11.4  

Solve:  

```{r}
#calculate c_k
c_k <- function(k,a){
  sqrt(a^2*k/(k+1-a^2))
}
equation <- function(k,a){
  pt(c_k(k-1,a),df = k-1) - pt(c_k(k,a),df = k)
}
root.curve <- sapply(c(4:25,100,500,1000),function(k){uniroot(equation,interval = c(0.0001,sqrt(k)-0.0001),k=k)$root}) 
#The lower bound of the root is slightly larger than 0, and the lower bound is slightly smaller than sqrt(k).
result <- data.frame(root.curve)

colnames(result) <- "root.curve"
rownames(result) <- as.character(c(4:25,100,500,1000))
knitr::kable(result)
```

# HW8-2020-11-24

## Question1-A-B-O blood  type   problem  

$\qquad$ Let the three alleles be A, B, and O.  
$\qquad$ Observed data: $n_{A.} = n_{AA} + n_{AO} = 444 (A-type),n_{B.} = n_{BB} + n_{BO} = 132 (B-type), n_{OO} = 361 (O-type),n_{AB} = 63 (AB-type)$.  

$\qquad$ Use EM algorithm to solve MLE of p and q (consider missing data $n_{AA}$ and $n_{BB}$).  

$\qquad$ Record the values of p and q that maximize the conditional likelihood in each EM steps, calculate the corresponding log-maximum likelihood values (for observed data), are they
increasing?  


## Answer1-A-B-O blood   type   problem  

Solve:
```{r}
#the initial parameter and observed data
set.seed(12345)
n_a. <- 444
n_b. <- 132
n_ab <- 63
n_oo <- 361
p0 <- runif(1,0,1)
q0 <- runif(1,0,1-p0)
p <- q <- ml <- numeric()
#E-step, calculate the expectation of log-likelihood function.
likelihood_e <- function(prob,p0,q0){
  r0 <- 1-p0-q0 
  p <- prob[1]; q <- prob[2] ; r <- 1-p-q
  - n_a. * (2*log(p)*(p0^2/(p0^2+2*p0*r0)) + log(2*p*r)*(2*p0*r0/(p0^2+2*p0*r0))) -
    n_b. * (2*log(q)*(q0^2/(q0^2+2*q0*r0)) + log(2*q*r)*(2*q0*r0/(q0^2+2*q0*r0))) -
    n_ab * log(2*p*q) - 2*n_oo * log(r) 
}
#M-step,use function optim() to maximize and renew the parameters.
iter <- 0;E1 <- 0;E2 <- 1
while(iter < 200 && abs(E1-E2)> 1e-6){
  output <- optim(par = c(0.1,0.1),likelihood_e,p0 = p0,q0 = q0)
  E1 <- E2;E2 <- output$value
  p0 <- output$par[1]
  q0 <- output$par[2]
  iter <- iter + 1
  p[iter] <- output$par[1]
  q[iter] <- output$par[2]
  ml[iter] <- output$value
}
estimate <- data.frame(p0,q0,iter)
colnames(estimate) <- c("p","q","iteration times")
knitr::kable(estimate)
#values of p and q that maximize the conditional likelihood in each EM steps,the corresponding log-maximum likelihood values 
result <- data.frame(p,q,-ml)
colnames(result) <- c("p","q"," ml")
knitr::kable(result)

```
From the results, this is increasing.


## Question2-Exercises 3  page204  


Use both for loops and lapply() to fit linear models to the
mtcars using the formulas stored in this list:  


```{r}
formulas <- list(
  mpg ~ disp,
  mpg ~ I(1 / disp),
  mpg ~ disp + wt,
  mpg ~ I(1 / disp) + wt
)
```


  

## Answer2-Exercises 3  page204  

Solve: 
```{r}
formulas <- list(
  mpg ~ disp,
  mpg ~ I(1 / disp),
  mpg ~ disp + wt,
  mpg ~ I(1 / disp) + wt
)

#Use for loops
models.loop <- list()
for(i in 1:length(formulas)){
  models.loop <- c(models.loop,list(lm(formulas[[i]],data = mtcars)))
}

#use lapply
models <- lapply(formulas,lm,data = mtcars)
models
```


## Question3-Exercises 3  

The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial.  

```{r}
trials <- replicate(
  100,
  t.test(rpois(10, 10), rpois(7, 10)),
  simplify = FALSE
)
```
  

Extra challenge: get rid of the anonymous function by using
[[ directly.


## Answer3-Exercises 3  


Solve:
```{r}
trials <- replicate(
  100,
  t.test(rpois(10, 10), rpois(7, 10)),
  simplify = FALSE
)
round(sapply(1:100,function(i){trials[[i]]$p.value}),3)

#Use the[[ to get rid of anonymous function.
round(sapply(trials,"[[","p.value"),3)
```

## Question4-Exercises 6  

Implement a combination of Map() and vapply() to create an lapply() variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take?  

## Answer4-Exercises 6  

Solve:
```{r}
testlist <- list(iris, mtcars, cars) 
lmapply <- function(X, FUN, FUN.VALUE, simplify = FALSE){ 
out <- Map(function(x) vapply(x, FUN, FUN.VALUE), X) 
if(simplify == TRUE){return(simplify2array(out))} 
out 
} 
lmapply(testlist, mean, numeric(1)) 
```

# HW9-2020-12-01

## Exercise 9.4 (page 277, Statistical Computing with R)  

$\quad$Write an Rcpp function for Exercise 9.4   
$\quad$Compare the corresponding generated random numbers with those by the R function you wrote before using the function “qqplot”.   

$\quad$Campare the computation time of the two functions with the function “microbenchmark”.   

$\quad$Comments your results.    

## Answer  

```{r}
rw.Metropolis <- function(x0,sigma,N) {
  #x0: the initial point
  #sigma: the standard deviation in the normal distribution
  #N: the length of the chain
  x <- numeric(N)
  x[1] <- x0
  u <- runif(N)
  accept <- 1 #count reject
  for(i in 2:N){
    y <- rnorm(1,x[i-1],sigma)
    if(u[i] < exp(abs(x[i-1])-abs(y))){
      x[i] <- y;accept <- accept + 1
    }else{
      x[i] <- x[i-1]
    }
  }
  return(list(x = x,accept = accept))
}

library(Rcpp)
cppFunction('List rw_Metropolis_c(double x0, double sigma, int N) {
  NumericVector x(N);
  as<DoubleVector>(x)[0] = x0;
  NumericVector u(N);
  u = as<DoubleVector>(runif(N));
  List out(2);
  int accept = 1;
  for(int i=1;i<N;i++){
    double y = as<double>(rnorm(1,x[i-1],sigma));
    if(u[i] <= exp(abs(x[i-1])-abs(y))){
        x[i] = y;accept = accept + 1;
    }
    else{
        x[i] = x[i-1];
    }
  }  
  out[0] = x;
  out[1] = accept;
  return(out);
}')
#Compare the generated random numbers by the two functions using qqplot
# the two chains
N = 5000; sigma = c(0.05,0.5,2,8);x0 = 10;
for(i in 1:length(sigma)){
  assign(paste0("chain",i),rw.Metropolis(x0,sigma[i],N))  
  assign(paste0("chain_c",i),rw_Metropolis_c(x0,sigma[i],N))  
}
for(i in 1:length(sigma)){
  par(mfrow = c(1,2))
  plot(get(paste0("chain",i))$x,type = "l", ylab = "from R",
       main = bquote(sigma == .(sigma[i])))
  plot(get(paste0("chain_c",i))[[1]],type = "l", ylab = "from Rcpp",
       main = bquote(sigma == .(sigma[i])))
}
#acceptance rate:
a <- data.frame(0)
for(i in 1:length(sigma)){
  a <- cbind(a,round(c(get(paste0("chain",i))$accept/N
                       ,get(paste0("chain_c",i))[[2]]/N),2))
  colnames(a)[i+1] <- paste0("sigma = ",sigma[i])
}
a <- a[2:5]
rownames(a) <- c("from R","from Rcpp")
knitr::kable(a)

for(i in 1:length(sigma)){
  qqplot(get(paste0("chain",i))$x,
         get(paste0("chain_c",i))[[1]],
         xlab = "from R",ylab = "from Rcpp",
         main = bquote(sigma == .(sigma[i])))
  f <- function(x) x
  curve(f, col = 'red',add = TRUE)
}
#we choose the median to compare consuming time of two chains
library(microbenchmark)
b <- data.frame(0)
ts1 <- microbenchmark(chain = rw.Metropolis(x0,sigma[1],N),
                      chain_c = rw_Metropolis_c(x0,sigma[1],N))
ts2 <- microbenchmark(chain = rw.Metropolis(x0,sigma[2],N),
                      chain_c = rw_Metropolis_c(x0,sigma[2],N))
ts3 <- microbenchmark(chain = rw.Metropolis(x0,sigma[3],N),
                      chain_c = rw_Metropolis_c(x0,sigma[3],N))
ts4 <- microbenchmark(chain = rw.Metropolis(x0,sigma[4],N),
                      chain_c = rw_Metropolis_c(x0,sigma[4],N))
for(i in 1:length(sigma)){
  b <- cbind(b,summary(get(paste0("ts",i)))$median)
  colnames(b)[i+1] <- paste0("sigma = ",sigma[i])
}
b <- b[2:5]
rownames(b) <- c("from R","from Rcpp")
knitr::kable(b)
```
Coments:  
1.From the figure, we conclude that if the generated chains converge, they have similar quantiles.  
2.We can conclude that the Rcpp function implement the same work as the R function do, the acceptance rate from two chains is similar, but Rcpp function consume much less time.


 



